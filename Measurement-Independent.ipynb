{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation\n",
    "\n",
    "In this section we generate all the data for training the model, using Haar states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Pauli Matrices\n",
    "# @markdown In this block we create a function to get all the Pauli matrices on an array.\n",
    "\n",
    "\n",
    "def pauli():\n",
    "  \"\"\"Get all the Pauli Matrices.\"\"\"\n",
    "  from numpy import zeros, array\n",
    "\n",
    "  s = zeros([3,2,2]) + 1j*zeros([3,2,2])\n",
    "  s[0] = array([[1, 0],[0, -1]])\n",
    "  s[1] = array([[0, 1],[ 1, 0]])\n",
    "  s[2] = array([[0, -1j],[1j, 0]])\n",
    "  return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Random Haar State\n",
    "# @markdown in this block we define a random Haar state generation function.\n",
    "\n",
    "def random_haar_state(dim,rank):\n",
    "  \"\"\"Generate a random Haar state.\"\"\"\n",
    "  import numpy.random as random\n",
    "  from numpy import divide, diagonal, identity, trace\n",
    "  import numpy.linalg as la\n",
    "\n",
    "  A = random.normal(0,1,(dim,dim))+1j*random.normal(0,1,(dim,dim))\n",
    "  q,r = la.qr(A,mode=\"complete\")\n",
    "  r  = divide(diagonal(r),abs(diagonal(r)))*identity(dim)\n",
    "  rU = q@r\n",
    "  B = random.normal(0,1,(dim,rank))+1j*random.normal(0,1,(dim,rank))\n",
    "  B = B@B.T.conj()\n",
    "  rho = (identity(dim)+rU)@B@(identity(dim)+rU.T.conj())\n",
    "  return rho/trace(rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Random Haar Pure State\n",
    "# @markdown In this block we define a random Haar pure state generation function.\n",
    "\n",
    "def random_haar_pure_state(dim,n):\n",
    "  \"\"\"Generate a random Haar pure state.\"\"\"\n",
    "  import numpy.linalg as la\n",
    "  from numpy import array, dot, random\n",
    "\n",
    "  rpure = random.normal(0,1,[dim,n]) + 1j*random.normal(0,1,[dim,n])\n",
    "  rpure = rpure/la.norm(rpure,axis=0)\n",
    "  rhon = array([dot(rpure[:,[i]],rpure[:,[i]].conjugate().transpose())  for i in range(n)])\n",
    "  # rhon = reshape(rhon,[n,4])\n",
    "  return rhon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Mutually Unbiased Basis Projectors\n",
    "# @markdown Here we define one qubit Pauli Projectors\n",
    "\n",
    "def mubpom():\n",
    "  \"\"\"Returns the 1-qubit Pauli projectors.\"\"\"\n",
    "  from numpy import array, zeros, sqrt, transpose, conjugate\n",
    "\n",
    "  p1 = array([1,0])\n",
    "  p2 = array([0,1])\n",
    "  mub = zeros([6,1,2])+1j*zeros([6,1,2])\n",
    "  mub[0] = p1\n",
    "  mub[1] = p2\n",
    "  mub[2] = 1/sqrt(2)*(p1+p2)\n",
    "  mub[3] = 1/sqrt(2)*(p1-p2)\n",
    "  mub[4] = 1/sqrt(2)*(p1+1j*p2)\n",
    "  mub[5] = 1/sqrt(2)*(p1-1j*p2)\n",
    "  mubp = [transpose(mub[i])@conjugate(mub[i]) for i in range(6)]\n",
    "  return mubp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Third Mutually Unbiased Basis\n",
    "# @markdown in this block we obtain the third mutually unbiased basis for the states generation.\n",
    "\n",
    "def mub3(nProj):\n",
    "  from numpy import linspace, sort, array, kron\n",
    "\n",
    "  mubsN = linspace(0,35,nProj,dtype=int)\n",
    "  mub = mubpom()\n",
    "  mub2 = array([kron(mub[i],mub[j])/9 for i in range(6) for j in range(6)])\n",
    "  mub3 = array([ mub2[n] for n in sort(mubsN[0:nProj]) ])\n",
    "  return mub3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Stokes from $\\rho$\n",
    "\n",
    "def stokes_from_rho(rho,A):\n",
    "  from numpy import shape, array, real, trace\n",
    "  l = shape(A)[0]\n",
    "  return array([ real(trace(rho@A[n])) for n in range(l) ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title $\\rho$ from Stokes\n",
    "\n",
    "def rho_from_stokes(stokes, A, dim):\n",
    "  from numpy import shape, identity, sum\n",
    "\n",
    "  l = shape(A)[0]\n",
    "  return 1/dim*(identity(dim)+sum([stokes[i]*A[i] for i in range(l)],axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Probability Distribution\n",
    "# @markdown In this block we define a function to get the probability distribution.\n",
    "\n",
    "def probdists(rho0, povm):\n",
    "  \"\"\"Get probabilities from quantum state rho0 and POVM.\"\"\"\n",
    "  from numpy import shape, array, real, trace, sum\n",
    "\n",
    "  l = shape(povm)[0]\n",
    "  probtrue = array([real(trace(rho0@povm[i])) for i in range(l)])\n",
    "  probtrue = probtrue/sum(probtrue)\n",
    "  return probtrue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Concurrence\n",
    "# @markdown In this block we define a function to get the real concurrence.\n",
    "\n",
    "def conc(A):\n",
    "  \"\"\"Get the real concurrence of an state.\"\"\"\n",
    "  from numpy import kron, conjugate, real, sort\n",
    "  import numpy.linalg as la\n",
    "  import scipy.linalg as sa\n",
    "\n",
    "  s = pauli()\n",
    "  s2 = kron(s[2],s[2])\n",
    "  At = (s2@conjugate(A))@s2\n",
    "  As = sa.sqrtm(A)\n",
    "  R = sa.sqrtm((As@At)@As)\n",
    "  eigval = real(sort(la.eig(R.astype(complex))[0])[::-1])\n",
    "  return max(0,eigval[0]-(eigval[1]+eigval[2]+eigval[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Herbasis\n",
    "\n",
    "def herbasis(dim):\n",
    "  from numpy import zeros, identity, dot, transpose, stack, concatenate\n",
    "\n",
    "  pom1 = zeros([1,dim,dim])+1j*zeros([1,dim,dim])\n",
    "  pom1[0] = identity(dim)\n",
    "  arrays = [dot(transpose(pom1[0][[i]]),pom1[0][[i]]) for i in range(dim-1)]\n",
    "  pom = stack(arrays,axis=0)\n",
    "  her = concatenate((pom1,pom),axis=0)\n",
    "  arrays = [dot(transpose(her[0][[i]]),her[0][[j]])+dot(transpose(her[0][[j]]),her[0][[i]]) for i in range(dim) for j in range(i+1,dim)]\n",
    "  pom = stack(arrays,axis=0)\n",
    "  her = concatenate((her,pom),axis=0)\n",
    "  arrays = [-1j*dot(transpose(her[0][[i]]),her[0][[j]])+1j*dot(transpose(her[0][[j]]),her[0][[i]]) for i in range(dim) for j in range(i+1,dim)]\n",
    "  pom = stack(arrays,axis=0)\n",
    "  pom = concatenate((her,pom),axis=0)\n",
    "  return pom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Pauli for Learning\n",
    "\n",
    "def pauli_for_learning(nProj):\n",
    "  from numpy import linspace, kron, array, sort\n",
    "\n",
    "  mubsN = linspace(0,35,nProj,dtype=int)\n",
    "  mub = mubpom()\n",
    "  mub2 = array([kron(mub[i],mub[j])/9 for i in range(6) for j in range(6)])\n",
    "  mub3 = array([ mub2[n] for n in sort(mubsN[0:nProj]) ])\n",
    "  return mub3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Gellmann\n",
    "\n",
    "def gellmann(Q,dim):\n",
    "  from numpy import zeros, trace, sqrt\n",
    "\n",
    "  q = zeros([dim**2,dim,dim])+1j*zeros([dim**2,dim,dim])\n",
    "  for i in range(dim**2):\n",
    "    v = Q[i]\n",
    "    for j in range(0,i):\n",
    "      v = v-trace(v@q[j])*q[j]\n",
    "    q[i] = v/sqrt(trace(v@v))\n",
    "  return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ttile GetR\n",
    "\n",
    "def getr():\n",
    "  from numpy import array, random\n",
    "\n",
    "  n = 0\n",
    "  p = array(range(36)[::-1])**2\n",
    "  p = p/sum(p)\n",
    "  k = random.multinomial(1,p)\n",
    "  while k[n]==0:\n",
    "    n+=1\n",
    "  return n,0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Data generation function\n",
    "# @markdown This blocks defines a function which generates data for the number of states given.\n",
    "\n",
    "def data_gen(quantity, nProj, dim, ll):\n",
    "  \"\"\"Generate the data to train a network.\"\"\"\n",
    "  from numpy import cbrt, random, arange, concatenate, sqrt, array, kron, ones, zeros, expand_dims\n",
    "\n",
    "  Q = herbasis(dim)\n",
    "  G_all = gellmann(Q,dim)*sqrt(dim)\n",
    "  G = G_all[1::]\n",
    "\n",
    "  mub = mubpom()\n",
    "  mub2 = array([kron(mub[i],mub[j])/9 for i in range(6) for j in range(6) ])\n",
    "\n",
    "  srmPOMs = array([ mub2 for k in range(quantity) ])\n",
    "  pomS = ones((quantity,36),dtype=int)\n",
    "\n",
    "\n",
    "  for n in range(quantity):\n",
    "    myList=list(range(nProj))\n",
    "    random.shuffle(myList)\n",
    "    # ~ k = 0\n",
    "    k = getr()[ll]\n",
    "    for i in myList[0:k]:\n",
    "      srmPOMs[n][i] = zeros([4,4],complex)\n",
    "      pomS[n][i] = 0\n",
    "\n",
    "  stokesFromPOMs = array([ array([ stokes_from_rho(srmPOMs[n][m],G_all) for m in range(nProj) ]) for n in range(quantity) ])\n",
    "\n",
    "  radius_list=cbrt(cbrt(cbrt(random.rand(int(quantity/5)))))\n",
    "  rhon = random_haar_pure_state(4,int(quantity/5))\n",
    "  stokes_list = array([ radius_list[n]*stokes_from_rho(rhon[n], G) for n in range(int(quantity/5)) ])\n",
    "  rhoList1 = array([ rho_from_stokes(stokes_list[n], G, dim) for n in range(int(quantity/5)) ])\n",
    "\n",
    "  rhoR1 = array([random_haar_state(4,1) for k in range(int(quantity/5))])\n",
    "  rhoR2 = array([random_haar_state(4,2) for k in range(int(quantity/5))])\n",
    "  rhoR3 = array([random_haar_state(4,3) for k in range(int(quantity/5))])\n",
    "  rhoR4 = array([random_haar_state(4,4) for k in range(int(quantity/5))])\n",
    "  rho_list = concatenate((rhoList1, rhoR1,rhoR2, rhoR3, rhoR4))\n",
    "\n",
    "  indxs = random.shuffle(arange(quantity))\n",
    "  rho_list = rho_list[indxs][0]\n",
    "\n",
    "  # ~ concurrence\n",
    "  y_train = array([conc(rho_list[n]) for n in range(int(4*quantity/5))])\n",
    "  y_val = array([conc(rho_list[n]) for n in range(int(4*quantity/5), quantity)])\n",
    "\n",
    "  # ~ probabilities\n",
    "  probListSRM = array([ probdists(rho_list[n],srmPOMs[n]) for n in range(quantity)])\n",
    "\n",
    "\n",
    "  x_train = array([probdists(rho_list[n],srmPOMs[n]) for n in range(int(4*quantity/5))])\n",
    "  x_val = array([probdists(rho_list[n],srmPOMs[n]) for n in range(int(4*quantity/5),quantity)])\n",
    "\n",
    "  for n in range(int(quantity*4/5)):\n",
    "    for i in range(nProj):\n",
    "      x_train[n,i*17:i*17+16] = stokesFromPOMs[n][i]\n",
    "      x_train[n,i*17+16] = probListSRM[n,i]\n",
    "\n",
    "  for n in range(int(quantity/5)):\n",
    "    for i in range(nProj):\n",
    "      x_val[n,i*17:i*17+16] = stokesFromPOMs[int(quantity*4/5)+n][i]\n",
    "      x_val[n,i*17+16] = probListSRM[int(quantity*4/5)+n,i]\n",
    "\n",
    "  return x_train,x_val,y_train,y_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement Independant DNN\n",
    "\n",
    "In this section we define the deep neural network for the measurement independent case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_independent_dnn():\n",
    "  \"\"\"Return a new model without training for the measurement independent case.\"\"\"\n",
    "  import keras\n",
    "\n",
    "  model = keras.Sequential()\n",
    "\n",
    "  model.add(keras.layers.Conv1D(100,\n",
    "    kernel_size=17,\n",
    "    strides=17,\n",
    "    input_shape=(17*36,1),\n",
    "    activation=\"relu\",\n",
    "    kernel_initializer=keras.initializers.glorot_normal(seed=42)\n",
    "  ))\n",
    "  model.add(keras.layers.Flatten())\n",
    "  model.add(keras.layers.Dense(120, activation=\"relu\", kernel_initializer=keras.initializers.glorot_normal(seed=42)))\n",
    "  model.add(keras.layers.Dense(80, activation=\"relu\", kernel_initializer=keras.initializers.glorot_normal(seed=42)))\n",
    "  model.add(keras.layers.Dense(70, activation=\"relu\", kernel_initializer=keras.initializers.glorot_normal(seed=42)))\n",
    "  model.add(keras.layers.Dense(60, activation=\"relu\", kernel_initializer=keras.initializers.glorot_normal(seed=42)))\n",
    "  model.add(keras.layers.Dense(50, activation=\"relu\", kernel_initializer=keras.initializers.glorot_normal(seed=42)))\n",
    "  model.add(keras.layers.Dense(40, activation=\"relu\", kernel_initializer=keras.initializers.glorot_normal(seed=42)))\n",
    "\n",
    "  model.add(keras.layers.Dense(1, activation=\"sigmoid\", kernel_initializer=keras.initializers.glorot_normal(seed=42)))\n",
    "\n",
    "  model.compile(loss=\"mse\", optimizer=\"Nadam\", metrics=[\"mean_absolute_error\"])\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Model Training\n",
    "# @markdown In this section we define the training strategy for the DNN.\n",
    "\n",
    "def train_measurement_independent_dnn():\n",
    "  from keras.callbacks import ModelCheckpoint\n",
    "  from numpy import savetxt\n",
    "\n",
    "  nProj = 36\n",
    "  dim = 4\n",
    "  noStates = 10000000\n",
    "\n",
    "  x_train,x_val,y_train,y_val = data_gen(200000,nProj,dim,1)\n",
    "\n",
    "  batch_size=500\n",
    "  epochs=100\n",
    "\n",
    "  bestModel = measurement_independent_dnn()\n",
    "  bestMAE = bestModel.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=0,\n",
    "    validation_data=(x_val, y_val)\n",
    "  )\n",
    "  bestModel.save(\"bestModelConcHaar.keras\")\n",
    "\n",
    "  for n in range(10):\n",
    "    print(n)\n",
    "    currentModel = measurement_independent_dnn()\n",
    "    currentMAE = bestModel.fit(\n",
    "      x_train, y_train,\n",
    "      batch_size=batch_size,\n",
    "      epochs=epochs,\n",
    "      verbose=0,\n",
    "      validation_data=(x_val, y_val)\n",
    "    )\n",
    "    if currentMAE.history[\"val_mean_absolute_error\"][-1]<bestMAE.history[\"val_mean_absolute_error\"][-1]:\n",
    "      bestMAE=currentMAE\n",
    "      bestModel=currentModel\n",
    "      bestModel.save(\"bestModelConcHaar.keras\")\n",
    "\n",
    "    print(bestMAE.history[\"val_mean_absolute_error\"][-1])\n",
    "\n",
    "  x_train,x_val,y_train,y_val = data_gen(noStates,nProj,dim,0)\n",
    "\n",
    "  filepath=\"bestModelConcHaar.keras\"\n",
    "\n",
    "  checkpoint = ModelCheckpoint(filepath, monitor=\"val_mean_absolute_error\", verbose=0, save_best_only=True, mode=\"min\")\n",
    "  callbacks_list = [checkpoint]\n",
    "\n",
    "  history = bestModel.fit(x_train, y_train,\n",
    "    batch_size=100,\n",
    "    epochs=2000,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks = callbacks_list\n",
    "  )\n",
    "\n",
    "  bestModel.save(\"bestModelConcHaar.keras\")\n",
    "  mse = history.history[\"mean_absolute_error\"]\n",
    "  val_mse = history.history[\"val_mean_absolute_error\"]\n",
    "  savetxt(\"trainingErrorsConc.txt\", [mse,val_mse], fmt=\"%s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_measurement_independent_dnn()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
